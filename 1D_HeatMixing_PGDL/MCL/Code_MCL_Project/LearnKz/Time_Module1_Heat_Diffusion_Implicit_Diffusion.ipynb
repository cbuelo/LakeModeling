{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<04:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.012964083220471035, Test_loss: 2.6567366512608713e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:09<03:10,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.3861857951269485e-05, Test_loss: 2.13462962013485e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:17<02:32,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 5.900962419631965e-06, Test_loss: 1.644835150121556e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:25<02:30,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 4.187519121759661e-06, Test_loss: 1.2985272132937097e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [00:33<02:26,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 3.448864741916292e-06, Test_loss: 9.989646590232345e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:41<02:09,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 3.384701926734124e-06, Test_loss: 7.630859984904722e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:50<02:11,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 3.259992168254526e-06, Test_loss: 6.063833620828518e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [00:59<02:18,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 2.9258170570756192e-06, Test_loss: 5.356807082534942e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [01:07<01:47,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 2.880466452511014e-06, Test_loss: 5.239650931798678e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:15<01:38,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 2.7877489401362254e-06, Test_loss: 5.524900067636432e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:24<01:33,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 2.719144070149262e-06, Test_loss: 5.243689565759269e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [01:33<01:22,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.7286757709920164e-06, Test_loss: 5.497548045241274e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [01:42<01:16,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.910873728400144e-06, Test_loss: 5.591424852961306e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [01:50<01:01,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.58861725073571e-06, Test_loss: 5.762653260414178e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [01:59<00:55,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.5652609203709953e-06, Test_loss: 5.911827990227417e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [02:07<00:43,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.790551134653056e-06, Test_loss: 6.006820315936541e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [02:15<00:38,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.5999176345563186e-06, Test_loss: 6.222418869583635e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [02:23<00:25,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.5038822596715446e-06, Test_loss: 6.386471720058277e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [02:33<00:24,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 2.551841574090345e-06, Test_loss: 6.5331381316961295e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:43<00:09,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.902642424115501e-06, Test_loss: 6.664244976188153e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:51<00:00,  5.82it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.015691307955652278\n",
      "L2 Error  of Temp: 0.0010806718790670568\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.010198850908775169\n",
      "L2 Error  of Temp: 0.0007967388357821287\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
