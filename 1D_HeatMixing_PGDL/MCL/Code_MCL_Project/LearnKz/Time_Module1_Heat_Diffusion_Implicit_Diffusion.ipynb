{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<03:50,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.007643219189379703, Test_loss: 0.00017894655732864824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:09<03:03,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.336394854495831e-05, Test_loss: 6.637277050079623e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:18<03:02,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 5.765989933272729e-06, Test_loss: 4.4756443412552474e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:27<02:48,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 4.544679251756117e-06, Test_loss: 3.3591759847695354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [00:36<02:36,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 3.721291312269221e-06, Test_loss: 2.6549266825289426e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:46<02:27,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 3.577399018633349e-06, Test_loss: 2.18482666999383e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:55<02:19,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 3.2004684633400093e-06, Test_loss: 1.7203562250263835e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [01:04<02:05,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 3.177960014578606e-06, Test_loss: 1.3615242179791191e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [01:13<01:59,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 3.2227803062183242e-06, Test_loss: 1.3047612424088583e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:22<01:50,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 2.984285825649832e-06, Test_loss: 1.0957793536666334e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:31<01:38,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 3.114890732418148e-06, Test_loss: 9.048111496667844e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [01:40<01:28,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.7866560117217887e-06, Test_loss: 9.019924179180332e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [01:50<01:16,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.703061599359816e-06, Test_loss: 9.079219610915364e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [01:59<01:08,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.5937882345384753e-06, Test_loss: 9.314129594410284e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [02:08<00:59,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.922690855071282e-06, Test_loss: 8.965191758155319e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [02:17<00:50,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.742452590031131e-06, Test_loss: 8.83066319753804e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [02:27<00:40,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.7816576872200214e-06, Test_loss: 8.93911305108001e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [02:36<00:29,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.713368928652926e-06, Test_loss: 8.903806406124205e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [02:46<00:19,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 2.7712801614722014e-06, Test_loss: 9.098233613258344e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:55<00:09,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.8562166831265627e-06, Test_loss: 8.823658655880232e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:04<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.017422625719558577\n",
      "L2 Error  of Temp: 0.001199909002350259\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.009753896602048766\n",
      "L2 Error  of Temp: 0.0007619788045307243\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
