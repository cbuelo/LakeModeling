{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<07:21,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.007431278333321891, Test_loss: 1.838287719995909e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:16<06:31,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.5225426068354864e-05, Test_loss: 0.00010667952507598481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [00:35<06:39,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 6.7865558280159765e-06, Test_loss: 8.26272768790659e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [00:52<05:08,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 4.825400930547568e-06, Test_loss: 6.967695153434761e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [01:11<05:43,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 4.037795106755353e-06, Test_loss: 5.509452006056866e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [01:31<06:28,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 3.6047591617137766e-06, Test_loss: 4.281271142948147e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [01:51<05:49,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 3.269374742971691e-06, Test_loss: 3.365474928311111e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [02:11<04:39,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 3.1446201453697786e-06, Test_loss: 2.547682750749421e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [02:32<07:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 3.0296806233888094e-06, Test_loss: 2.2066213568905367e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [02:53<03:55,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 3.1263273389082644e-06, Test_loss: 1.860570450844534e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [03:12<03:31,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 2.6757519900787554e-06, Test_loss: 1.633671909075929e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [03:30<03:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.6836383374922495e-06, Test_loss: 1.6489216219876348e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [03:49<03:01,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.6742432417201845e-06, Test_loss: 1.624560727577773e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [04:08<02:23,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.6100513588806446e-06, Test_loss: 1.579627246428572e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [04:27<02:09,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.8388783965221425e-06, Test_loss: 1.5425466851108165e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [04:45<01:46,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.8193583199770895e-06, Test_loss: 1.5202392857342299e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [05:04<01:28,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.624431105728449e-06, Test_loss: 1.4754632760135185e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [05:23<01:04,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.708763402510654e-06, Test_loss: 1.4870400400468498e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [05:38<00:29,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 3.1400804180686297e-06, Test_loss: 1.4185258169163718e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [05:48<00:09,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.735557054413882e-06, Test_loss: 1.4371386411463997e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:57<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.022083856053292477\n",
      "L2 Error  of Temp: 0.0015209313516507245\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.009728420325032117\n",
      "L2 Error  of Temp: 0.0007599885862726221\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
