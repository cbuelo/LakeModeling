{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'diffusivity' ,'temp_heat00']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 13, 14]\n",
      "13\n",
      "5\n",
      "[0, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_column_ix[13])\n",
    "print(input_column_ix[5])\n",
    "print(input_column_ix[:2])\n",
    "print(input_column_ix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<10:02,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.012776152442463419, Test_loss: 4.339677010041972e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:16<06:29,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.5938307363037232e-05, Test_loss: 2.8210220398250387e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [00:38<07:56,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 6.5467188505863305e-06, Test_loss: 2.2544950411429454e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [00:59<06:47,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 4.53646787884116e-06, Test_loss: 1.9359582908388498e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [01:19<06:22,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 3.695050519457833e-06, Test_loss: 1.861577782923026e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [01:39<05:47,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 3.217984871381222e-06, Test_loss: 1.7735511679954167e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [02:03<06:24,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 3.2629733161890973e-06, Test_loss: 1.709925750219554e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [02:27<06:33,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 3.1506524154875395e-06, Test_loss: 1.5842752115228603e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [02:56<06:24,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 3.2212531871002947e-06, Test_loss: 1.416928022687595e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [03:18<03:03,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 2.8630156831158358e-06, Test_loss: 1.3533439247718585e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [03:33<02:48,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 2.810559072424274e-06, Test_loss: 1.2859019731574032e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [03:48<02:39,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.595836659483294e-06, Test_loss: 1.2919507419913619e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [04:04<02:44,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.6854491517786467e-06, Test_loss: 1.2963088299026519e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [04:21<02:28,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.7420710776740718e-06, Test_loss: 1.280927108382457e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [04:49<04:15,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.63830791234134e-06, Test_loss: 1.2668967247009278e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [05:07<01:45,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.5352772623095503e-06, Test_loss: 1.2556130362402959e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [05:23<01:07,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.685329739258371e-06, Test_loss: 1.2426787876999395e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [05:40<01:17,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.794643354387848e-06, Test_loss: 1.2401483415184581e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [05:58<00:42,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 2.6352002309563845e-06, Test_loss: 1.242136581822706e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [06:15<00:17,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.519862766286513e-06, Test_loss: 1.2179283233611689e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:29<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,14] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,14]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.020800721609273612\n",
      "L2 Error  of Temp: 0.0014325609420817733\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.009742643229891322\n",
      "L2 Error  of Temp: 0.0007610996860190859\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
