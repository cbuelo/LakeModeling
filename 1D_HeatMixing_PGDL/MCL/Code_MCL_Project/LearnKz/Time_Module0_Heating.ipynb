{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1','Area_m2', \n",
    "                 'day_of_year', 'time_of_day', 'input_temp']\n",
    "output_columns = ['temp_heat00']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 11), X_test: (14150, 11)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=11, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<03:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.8740106735910688, Test_loss: 1.1383646087987083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:06<02:17,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.0005860211621482103, Test_loss: 0.07586402525859219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:13<02:24,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 0.0001857392697794629, Test_loss: 0.03499915255399953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:20<02:01,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 9.452744728020792e-05, Test_loss: 0.029187987533597543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [00:27<02:16,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 6.20466794533145e-05, Test_loss: 0.029752776908156062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:34<01:47,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 4.8233211557436294e-05, Test_loss: 0.02867273545624422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:40<01:53,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 4.103562536156027e-05, Test_loss: 0.02714999738548483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [00:47<01:28,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 3.6603698303917466e-05, Test_loss: 0.02272223851676764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:53<01:26,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 3.691583472010236e-05, Test_loss: 0.017574193509062752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:00<01:19,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 3.05238807500462e-05, Test_loss: 0.01510077458806336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:06<01:09,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 2.7206051440554714e-05, Test_loss: 0.013683059136383235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [01:13<01:02,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 2.6274289883163182e-05, Test_loss: 0.012871389784517564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [01:19<01:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 2.622136742588953e-05, Test_loss: 0.012776886967393304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [01:26<00:49,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 2.6555147217420328e-05, Test_loss: 0.012072933947950202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [01:32<00:45,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 2.5921597192618285e-05, Test_loss: 0.01192807060683013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [01:38<00:35,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 2.59314096010279e-05, Test_loss: 0.011589527836934264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [01:45<00:30,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.50999252048565e-05, Test_loss: 0.010710657532659493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [01:51<00:20,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 2.4877849465978908e-05, Test_loss: 0.010738152549103168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [01:58<00:16,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 2.4786199511644164e-05, Test_loss: 0.010194979084189981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:05<00:06,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 2.456458822139428e-05, Test_loss: 0.009344033427104088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:11<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.5732848845819865\n",
      "L2 Error  of Temp: 0.03948138483956508\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.029018472143808188\n",
      "L2 Error  of Temp: 0.0022671866058075326\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heating_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34450246])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
