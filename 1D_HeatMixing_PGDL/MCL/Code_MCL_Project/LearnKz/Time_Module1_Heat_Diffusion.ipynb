{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 14), X_test: (14150, 14)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=14, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(self, temp, mean=0.0, std=1.0):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    # std = torch.tensor(std).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    self = self * std + mean\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp # temperature profile from previous module output\n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = self #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = torch.zeros((len(t), len(t)))\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean)/std\n",
    "\n",
    "\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/1000 [00:10<2:49:27, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 1.998694618542989, Test_loss: 2.1186267052377974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 51/1000 [07:11<2:23:15,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.9975945495423817, Test_loss: 2.118626730782645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 101/1000 [14:15<2:18:37,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 1.9991958425158547, Test_loss: 2.118626756327493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 151/1000 [21:22<2:07:09,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 1.9979921409061976, Test_loss: 2.118626756327493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 201/1000 [28:25<1:59:00,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 1.9988011292048864, Test_loss: 2.1186267222676958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 251/1000 [35:30<1:52:34,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 2.00034000760033, Test_loss: 2.1186267222676958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 301/1000 [42:33<1:43:46,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 1.997878733135405, Test_loss: 2.118626696722848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▎                        | 351/1000 [49:32<1:36:41,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 1.9987450611023676, Test_loss: 2.118626671178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 401/1000 [56:34<1:30:39,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 2.000206913266863, Test_loss: 2.118626756327493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████▏                   | 451/1000 [1:03:32<1:21:10,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 2.0004485618500483, Test_loss: 2.118626739297594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████                  | 501/1000 [1:10:27<1:13:33,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 1.9997023684637887, Test_loss: 2.118626764842442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████▊                | 551/1000 [1:17:23<1:06:13,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 1.9989794152123588, Test_loss: 2.118626688207899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 601/1000 [1:24:18<59:06,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 1.9981814509346372, Test_loss: 2.118626671178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 651/1000 [1:31:13<51:38,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 1.999580218678429, Test_loss: 2.118626739297594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▋           | 701/1000 [1:38:07<44:07,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 1.9987072774342127, Test_loss: 2.1186268074171886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████▌         | 751/1000 [1:45:01<36:35,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 1.9988547904150826, Test_loss: 2.118626756327493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 801/1000 [1:51:56<29:16,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 2.0000965027582076, Test_loss: 2.118626764842442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████▎     | 851/1000 [1:58:51<22:02,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 1.9993318092255365, Test_loss: 2.118626756327493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████▏   | 901/1000 [2:05:45<14:37,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 1.9995697282609486, Test_loss: 2.118626739297594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████▏ | 951/1000 [2:12:40<07:13,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 1.9985991035188948, Test_loss: 2.1186266796929494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [2:19:24<00:00,  8.36s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        mean=0.0\n",
    "        std=1.0\n",
    "        mean = torch.tensor(mean).to(device)\n",
    "        std = torch.tensor(std).to(device)\n",
    "        temp_input = x[:,13] * std + mean\n",
    "        #print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            mean=0.0\n",
    "            std=1.0\n",
    "            mean = torch.tensor(mean).to(device)\n",
    "            std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] * std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 15.38739586524569\n",
      "L2 Error  of Temp: 1.0597412306635514\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 17.599125198322444\n",
      "L2 Error  of Temp: 1.3748516030595952\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
