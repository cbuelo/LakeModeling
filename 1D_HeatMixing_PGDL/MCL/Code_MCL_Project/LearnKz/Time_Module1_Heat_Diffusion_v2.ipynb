{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ladwi\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(diff, temp, mean, std, mean2, std2):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    # std = torch.tensor(std).to(device)\n",
    "    mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "    std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "    \n",
    "    mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "    std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "    \n",
    "    mean_out = torch.tensor(mean2).to(device)\n",
    "    std_out = torch.tensor(std2).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    \n",
    "    #print(t)\n",
    "    \n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = diff #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)))\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "    \n",
    "    y = torch.diag(bz[:, 0])+torch.diag(az[:-1, 0],-1)+torch.diag(cz[:-1, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[j-1, j-1] = 1\n",
    "    \n",
    "#     # tridiagonal matrix\n",
    "#     for k in range(j-1):\n",
    "#         y[k][k] = bz[k]\n",
    "#         y[k][k+1] = cz[k]\n",
    "#         y[k+1][k] = az[k]\n",
    "\n",
    "    \n",
    "\n",
    "    mn = torch.zeros_like(t)    \n",
    "    mn[0] = t[0]\n",
    "    mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "#     for k in range(1,j-1):\n",
    "#         mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "    proj = proj.to(torch.double)\n",
    "\n",
    "#     proj = proj.float()\n",
    "\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j= 5\n",
    "# alpha = torch.tensor([1.,2.,3.,4.,5.])\n",
    "# y = torch.zeros(5, 5)\n",
    "# az = alpha # subdiagonal\n",
    "# bz = 2 * (1 + alpha) # diagonal\n",
    "# cz = -alpha # superdiagonal\n",
    "\n",
    "# bz[0] = 1\n",
    "# az[len(az)-2] = 0\n",
    "# bz[len(bz)-1] = 1\n",
    "# cz[0] = 0\n",
    "\n",
    "# # tridiagonal matrix\n",
    "# for k in range(j-1):\n",
    "#     y[k][k] = bz[k]\n",
    "#     y[k][k+1] = cz[k]\n",
    "#     y[k+1][k] = az[k]\n",
    "\n",
    "# y[j-1, j-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 14, 13]\n",
      "[ 1.30000000e+01  1.93619387e+01  7.97611281e+02 -1.27637027e+02\n",
      " -1.68297160e+01  2.36993670e+02  4.08006076e-01  2.30560213e+00\n",
      "  8.82174601e-03  3.60000000e+07  8.40535870e-04  1.72232038e+02\n",
      "  1.14310954e+01  1.13445025e+01  2.07829505e-05]\n",
      "2.0782950512289867e-05\n",
      "[11.34604205]\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_mean)\n",
    "print(input_mean[input_column_ix[13]])\n",
    "print(output_mean)\n",
    "#print(torch.tensor(input_mean[input_column_ix][14]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1)\n",
    "# diff = torch.rand(5,1)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:05<1:30:19,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 1.7888697329021634, Test_loss: 1.8153267216550184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:46<13:39,  1.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.4337397529965354, Test_loss: 1.6889091845876265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [01:27<13:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 1.433916029475984, Test_loss: 1.656716921877896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [02:07<12:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 1.4322240068798973, Test_loss: 1.661400796290905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [02:47<11:31,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 1.4294485251108806, Test_loss: 1.701295205273828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [03:28<10:43,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 1.432945308231172, Test_loss: 1.6378622309804878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [04:08<10:10,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 1.4340695256278628, Test_loss: 1.671322801792401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [04:48<09:18,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 1.4270649410429455, Test_loss: 1.6445005912376132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [05:29<08:53,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 1.4311351832889376, Test_loss: 1.6561252969881142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [06:09<07:49,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 1.4332551899410428, Test_loss: 1.6382529752817414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [06:50<07:20,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 1.4325730403264363, Test_loss: 1.6547692750619731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [07:30<06:23,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 1.4309745516095842, Test_loss: 1.6582664881435156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [08:11<05:49,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 1.4315287045070104, Test_loss: 1.6672780351950247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [08:51<05:10,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 1.4340961433592296, Test_loss: 1.6672585854420696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [09:35<04:49,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 1.4286917448043823, Test_loss: 1.679845307978343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [10:18<03:42,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 1.429987873349871, Test_loss: 1.669915204440619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [10:59<02:53,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 1.4317710740225655, Test_loss: 1.6737687965534405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [11:39<02:07,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 1.4347273054577054, Test_loss: 1.6697819832000922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [12:20<01:24,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 1.4319050312042236, Test_loss: 1.6755073322246787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [13:00<00:42,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 1.4310095253444852, Test_loss: 1.6697734449501833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [13:39<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        #print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        \n",
    "        #print(proj)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        #print(pred)\n",
    "        #print(y)\n",
    "        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        #print(loss)\n",
    "        #loss= loss.double\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            #mean=0.0\n",
    "            #std=1.0\n",
    "            #mean = torch.tensor(mean).to(device)\n",
    "            #std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        #red = torch.squeeze(pred)\n",
    "        \n",
    "        #rint(pred.shape)\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_)\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 4.4851874869722925\n",
      "L2 Error  of Temp: 0.3088981494221723\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 4.4224851352218675\n",
      "L2 Error  of Temp: 0.3454865346515398\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.34604205])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
