{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 14), X_test: (14150, 14)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=14, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(self, temp, mean=0.0, std=1.0):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    #std = torch.tensor(std).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    self = self * std + mean\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp # temperature profile from previous module output\n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = self #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = torch.zeros((len(t), len(t)))\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(proj.reshape(-1, 1))\n",
    "    \n",
    "    # normalise data back\n",
    "    proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1121, 25.9411, 44.6591,  ..., 12.3553,  1.4955, -0.7217],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-1.1133],\n",
      "        [-0.1131],\n",
      "        [ 0.1180],\n",
      "        ...,\n",
      "        [ 0.1369],\n",
      "        [-0.6163],\n",
      "        [-0.7218]])\n",
      "tensor([-0.3868, -0.3892, -0.4975,  ...,  0.4022,  1.1847,  1.8983],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.3867],\n",
      "        [-0.0621],\n",
      "        [ 1.3688],\n",
      "        ...,\n",
      "        [-1.1321],\n",
      "        [-0.2284],\n",
      "        [ 1.8948]])\n",
      "tensor([ 1.5622, -1.3576,  1.5580,  ..., -0.7209,  0.3086,  0.1875],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 1.5626],\n",
      "        [ 0.0909],\n",
      "        [-0.9424],\n",
      "        ...,\n",
      "        [ 0.5633],\n",
      "        [ 0.9347],\n",
      "        [ 0.1872]])\n",
      "tensor([ 0.9142, -0.2367,  2.0157,  ...,  0.0450, -0.4730, -0.9340],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.9181],\n",
      "        [ 3.3558],\n",
      "        [-0.4384],\n",
      "        ...,\n",
      "        [-0.0507],\n",
      "        [ 0.9726],\n",
      "        [-0.9341]])\n",
      "tensor([-1.0380, -1.4012,  1.3392,  ...,  2.1038,  2.8510,  1.4079],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-1.0382],\n",
      "        [-1.2918],\n",
      "        [ 1.4487],\n",
      "        ...,\n",
      "        [-1.2094],\n",
      "        [-0.3036],\n",
      "        [ 1.4088]])\n",
      "tensor([ 1.1829, -0.1059, -0.3757,  ..., -0.4053, -2.5712,  0.0992],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 1.1826],\n",
      "        [-0.5773],\n",
      "        [ 0.3228],\n",
      "        ...,\n",
      "        [-1.1234],\n",
      "        [-0.1101],\n",
      "        [ 0.0952]])\n",
      "tensor([ 0.1185, -0.0628,  0.0138,  ...,  2.5677,  0.2292, -0.5746],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.1188],\n",
      "        [ 0.0052],\n",
      "        [-0.2411],\n",
      "        ...,\n",
      "        [-1.1176],\n",
      "        [ 1.4336],\n",
      "        [-0.5747]])\n",
      "tensor([-0.7754,  0.0510,  0.1172,  ...,  0.6494, -1.2752, -0.7057],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.7751],\n",
      "        [-0.1857],\n",
      "        [-0.4559],\n",
      "        ...,\n",
      "        [-0.6775],\n",
      "        [ 1.7992],\n",
      "        [-0.7057]])\n",
      "tensor([-0.4022, -0.5957,  0.1635,  ...,  0.0774, -0.3152, -0.6510],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.4017],\n",
      "        [ 0.9181],\n",
      "        [ 0.6044],\n",
      "        ...,\n",
      "        [ 0.5115],\n",
      "        [ 1.1009],\n",
      "        [-0.6510]])\n",
      "tensor([ 0.4831,  1.4299, -0.2339,  ..., -1.6673, -0.6561, -1.0986],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.4843],\n",
      "        [-0.7628],\n",
      "        [ 0.9072],\n",
      "        ...,\n",
      "        [ 1.7756],\n",
      "        [ 0.5846],\n",
      "        [-1.0987]])\n",
      "tensor([-0.0823,  0.0541,  0.0780,  ..., -0.5484,  0.9309,  1.6420],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.0821],\n",
      "        [-0.1173],\n",
      "        [-0.1312],\n",
      "        ...,\n",
      "        [ 1.7508],\n",
      "        [-1.0262],\n",
      "        [ 1.6421]])\n",
      "tensor([-0.1750, -0.5626, -2.0793,  ...,  1.3956,  1.0694,  0.1099],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.1748],\n",
      "        [-1.1933],\n",
      "        [ 2.3909],\n",
      "        ...,\n",
      "        [-0.9516],\n",
      "        [ 0.4809],\n",
      "        [ 0.1095]])\n",
      "tensor([ 0.0796, -0.7387, -0.4125,  ...,  0.2605, -0.2827, -0.4927],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.0795],\n",
      "        [ 0.8779],\n",
      "        [ 0.8523],\n",
      "        ...,\n",
      "        [-0.2922],\n",
      "        [ 0.5858],\n",
      "        [-0.4926]])\n",
      "tensor([-1.1415, -0.3134,  0.1726,  ..., -0.4695,  1.8168,  2.4022],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-1.1416],\n",
      "        [-0.7050],\n",
      "        [-0.2396],\n",
      "        ...,\n",
      "        [ 1.2077],\n",
      "        [ 1.3785],\n",
      "        [ 2.4054]])\n",
      "tensor([-1.2885,  0.0071,  0.0292,  ...,  0.2554, -0.2270,  0.1233],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-1.2887],\n",
      "        [ 0.1599],\n",
      "        [-0.0027],\n",
      "        ...,\n",
      "        [-0.8838],\n",
      "        [ 0.8977],\n",
      "        [ 0.1227]])\n",
      "tensor([-0.9130, -1.1343,  1.4479,  ...,  2.0332,  0.1667,  1.1025],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.9134],\n",
      "        [ 1.4823],\n",
      "        [-1.0401],\n",
      "        ...,\n",
      "        [-0.4101],\n",
      "        [-1.1641],\n",
      "        [ 1.1025]])\n",
      "tensor([-0.3998,  0.2085,  0.1823,  ...,  0.8627,  0.9335,  1.3909],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.3998],\n",
      "        [-0.0597],\n",
      "        [-1.1026],\n",
      "        ...,\n",
      "        [-0.8017],\n",
      "        [-0.7253],\n",
      "        [ 1.3888]])\n",
      "tensor([ 0.4598,  0.6506, -0.0242,  ..., -0.7221, -0.3034,  0.1319],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.4605],\n",
      "        [-0.0652],\n",
      "        [-0.0176],\n",
      "        ...,\n",
      "        [ 0.3586],\n",
      "        [-0.3609],\n",
      "        [ 0.1303]])\n",
      "tensor([-0.2678, -0.6507, -0.4388,  ...,  0.0110, -0.1935, -0.3780],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.2670],\n",
      "        [ 0.6133],\n",
      "        [ 0.4207],\n",
      "        ...,\n",
      "        [-0.8864],\n",
      "        [ 0.2207],\n",
      "        [-0.3779]])\n",
      "tensor([-0.3985,  0.0725,  1.3029,  ...,  0.0241, -1.2713, -0.1713],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.3984],\n",
      "        [ 0.6499],\n",
      "        [ 0.2243],\n",
      "        ...,\n",
      "        [-0.9337],\n",
      "        [-0.9136],\n",
      "        [-0.1711]])\n",
      "tensor([ 1.9693e+00, -7.8632e+00,  1.0371e-01,  4.6700e-01, -1.9700e+00,\n",
      "        -4.8846e-01,  9.0095e-01,  1.4270e+00,  3.2228e+00,  1.3311e+01,\n",
      "         2.6576e+01, -1.2712e+00, -6.9216e+00, -2.3512e-01,  1.8688e+00,\n",
      "        -1.9007e-01, -4.6060e-03, -7.1569e-01, -6.7220e-02,  1.6128e+00,\n",
      "         3.3921e-01, -9.3217e-01,  7.8399e-01,  3.6608e-01,  1.7149e-01,\n",
      "        -2.7937e-02,  4.0313e-02,  3.7887e+00, -1.1063e-01,  1.4827e+00,\n",
      "         9.3934e+00,  3.1730e-01,  2.3247e-01, -4.8054e-02,  5.5665e-01,\n",
      "        -9.8840e-01,  8.9805e-01, -1.0190e-01,  2.8248e-02, -5.0360e-01,\n",
      "         4.8542e-01, -1.3901e-01,  1.2282e-01,  8.4925e-02, -2.6354e-01,\n",
      "        -3.2846e-01, -7.7946e-01, -1.3184e-01, -5.5091e-02, -2.3985e-01,\n",
      "        -1.9148e-01,  4.4339e-01, -1.1967e-01, -4.1529e-02,  1.9227e-01,\n",
      "         8.6237e-01, -1.2242e+00, -1.2115e+00, -2.6436e+00,  4.8849e-02,\n",
      "         3.2946e-01, -5.4146e-01, -6.8153e-02, -4.1559e-01, -6.0688e-02,\n",
      "        -9.2455e-02,  1.6469e+00, -5.8581e-01,  6.2088e-02, -1.4611e-01,\n",
      "         1.1833e+00, -2.3874e+00, -2.2068e+00,  4.6102e-01, -1.0107e+00,\n",
      "         2.9899e-01,  2.1170e+00,  1.3052e+00,  3.0687e-01,  6.9875e-01,\n",
      "        -3.3442e-01,  4.8497e-01, -9.9191e-01,  1.1877e-01,  1.2199e+00,\n",
      "        -7.8790e-01, -6.6454e-01, -6.2946e-01, -3.0969e-01,  2.6914e-01,\n",
      "         5.0370e-01,  5.2122e-04,  1.2875e+00,  8.8868e-01,  2.3512e+00,\n",
      "         3.4951e+00, -1.7851e+00, -1.0017e+00,  6.2879e-01, -4.6225e-01,\n",
      "         6.5260e-03,  5.4889e-01, -3.2998e-01, -5.5990e-01,  2.2670e-03,\n",
      "        -7.5156e-01, -1.1686e+00,  1.8267e-01,  1.1291e+00, -2.3938e-01,\n",
      "         5.5694e-01,  5.4812e-02, -3.4452e-01,  6.5878e-01,  1.0701e+00,\n",
      "        -1.7594e+00, -2.2090e+00, -3.6639e-01,  1.2108e-01,  1.1567e-02,\n",
      "         6.9186e-01,  9.0964e-01,  2.2853e+00,  4.0564e+00,  1.1176e+01,\n",
      "         2.4385e+01,  5.3526e+00, -1.2697e+01,  4.5256e-01, -4.3892e-01,\n",
      "        -9.3897e-03,  1.4997e-01,  5.1081e-01, -1.5975e-01, -3.7681e-02,\n",
      "         3.3064e-02,  5.3114e-01,  1.5519e-01, -1.0658e+00,  1.1207e+00,\n",
      "        -5.7876e-01,  1.3429e+00, -1.9191e+00,  4.0536e-02,  9.0094e-02,\n",
      "         1.4855e+00,  1.2508e-01, -2.4783e-01,  1.2862e-01,  5.5172e-01,\n",
      "        -1.0714e-01, -1.7362e-02,  2.9158e-01,  2.2844e-01,  2.0978e-01,\n",
      "         4.5473e-01,  6.0070e-02,  2.0320e+00, -8.7240e-01,  1.6114e+00,\n",
      "         2.4500e-02,  2.7626e-01,  3.2451e-02, -1.0989e+00,  8.7593e-01,\n",
      "        -4.7083e-01,  1.6629e-01, -1.4906e+00, -2.7694e+00,  4.0892e-02,\n",
      "        -8.9238e-02, -1.3624e-01, -7.6325e-01, -1.2194e-01, -1.8565e-01,\n",
      "         5.0255e-01, -3.7442e-03,  6.3396e-01, -1.1622e-01,  7.0838e-02,\n",
      "         5.4474e-01, -6.3211e-01, -8.0592e-01,  8.4249e-01, -2.6904e-01,\n",
      "        -9.4427e-01,  1.2475e-01, -3.2857e+00,  8.5084e-02, -4.0160e-01,\n",
      "        -3.8112e-01,  8.9447e-01, -6.9557e-01, -1.1375e-01, -1.3355e+00,\n",
      "        -4.8694e-01, -4.0638e+00, -9.2760e-02, -3.0726e-01, -1.0864e+00,\n",
      "        -3.5105e-01,  2.0088e-01, -1.1845e-03,  6.1139e-02,  1.3702e-01,\n",
      "        -1.1404e-01,  4.5000e-01,  7.1804e-02, -2.6722e-01, -3.3316e-02,\n",
      "         2.9385e-01,  1.2306e+00,  2.7669e+00,  3.5801e+00,  8.0249e+00,\n",
      "         4.3484e+01,  8.5637e+01,  1.1173e+00, -2.6616e+00,  8.5443e+00,\n",
      "         2.9299e+00, -9.0008e-03, -6.6254e-02,  1.4387e+00, -3.4210e-01,\n",
      "        -3.7385e-01,  1.2059e+00, -3.9323e-01, -2.1534e-01,  1.1864e-01,\n",
      "         7.5689e-01,  3.8149e+00,  5.7657e+00, -1.8675e+00, -4.7230e-01,\n",
      "         2.9182e+00, -1.7054e+00, -1.7738e-01,  1.6375e-01, -5.4980e-02,\n",
      "         2.9070e-01,  2.0696e-01,  8.7091e-01,  5.4046e-01, -1.9821e+00,\n",
      "        -2.8080e+00, -1.7056e+00, -9.4826e-01, -2.9764e+00, -2.7287e+00,\n",
      "        -3.7506e+00, -3.1837e+00, -4.4632e-01,  5.3268e-01, -2.7511e-01,\n",
      "         5.6449e-03,  2.6003e-01,  7.3475e-02, -2.2407e-01,  6.6138e-01,\n",
      "        -4.4902e-01,  8.5632e-01, -4.3657e-01, -2.7435e+00, -4.7013e+00,\n",
      "        -1.0111e+01, -5.2068e-01,  1.3787e+00,  6.9399e-01, -2.1052e-01,\n",
      "         1.4232e-02, -2.8684e-02, -2.6812e-01,  6.2660e-01, -4.3616e-01,\n",
      "        -8.2693e-01, -2.8641e+00, -3.8944e+00,  1.4927e+00,  1.0056e+00,\n",
      "        -1.3849e-01,  1.8873e+00,  3.0615e-01, -9.6193e-01,  3.0392e+00,\n",
      "         7.2599e+00,  4.6765e-01, -3.0349e+00, -3.4952e-01,  4.4452e-01,\n",
      "        -2.4955e-01,  2.5003e-01,  2.2682e-01, -7.9422e-02,  1.9886e+00,\n",
      "         7.2423e-01, -1.0290e-01, -2.3204e-01,  4.2367e-01,  1.9041e-02,\n",
      "         2.8632e-01, -1.9923e-01,  2.6590e+00,  1.5321e+00, -1.0761e-01,\n",
      "         1.7691e-01,  4.5361e-01,  6.5430e-02, -3.7675e-02,  1.6947e-01,\n",
      "        -3.8405e-01, -1.5075e-02,  6.6851e-01,  2.8593e-01,  7.6318e-01,\n",
      "         1.4481e+00, -4.9490e-03,  1.3305e+00, -2.8248e-01,  7.8446e-01,\n",
      "         7.6648e-01,  8.1818e-01,  3.7754e+00,  2.6487e-01,  5.0849e-01,\n",
      "        -2.0288e-01, -5.2513e-02,  6.1963e-01,  5.8729e-01, -6.7122e-01,\n",
      "        -8.2663e-02,  1.7006e+00, -2.6484e-01,  5.8647e-01,  2.2064e+00,\n",
      "        -2.4205e-01,  9.5322e-01,  1.1153e-02, -2.9604e-01, -2.0586e-01,\n",
      "        -3.3587e-01, -1.6354e+00, -5.6539e-01, -1.6065e+00, -1.2359e+00,\n",
      "        -8.5237e+00, -2.8460e+00, -1.5348e+00,  2.6920e-01,  6.6715e-01,\n",
      "         2.8801e+00,  2.4005e-01, -1.4828e+00, -2.9634e+00, -1.0610e+01,\n",
      "        -1.9800e+01, -6.5125e+01,  7.5523e+00,  2.5042e+01, -1.7989e+01,\n",
      "        -5.9251e+00, -2.9428e+01, -6.7141e-01, -6.9982e-01,  4.3649e-01,\n",
      "        -1.5825e+00, -1.1421e+00,  9.5045e-01, -3.8998e-01,  2.3606e-01,\n",
      "        -8.1062e-01, -3.1049e-01, -7.8303e-01, -7.6756e-01, -1.1947e+00,\n",
      "         5.3880e-01, -1.5465e-02, -2.8652e-01,  5.1812e-02,  4.7815e-02,\n",
      "         1.3594e+00,  1.0294e-02,  9.0690e-01,  1.5472e-02, -2.4191e-01,\n",
      "         1.0175e-02,  6.2426e-01,  1.5068e+00,  2.8660e+00,  2.5221e+00,\n",
      "         5.4730e+00,  4.9616e+00,  2.4149e+01,  1.7852e+00,  1.9884e-01,\n",
      "         2.6327e+00,  4.5927e+00,  9.9444e+00, -6.3261e+00,  3.3687e+00,\n",
      "        -2.7241e-01,  1.3288e+00, -4.8645e-01,  1.0744e+00, -7.8764e-02,\n",
      "         3.5635e-01,  3.3340e-02,  2.5824e+00,  2.0719e-02,  6.7934e-01,\n",
      "         6.6109e-01, -4.7035e-01,  5.5734e-01,  1.0259e+00,  1.4716e+00,\n",
      "         5.8620e+00, -3.7543e+00, -6.7807e+00, -1.3479e+00, -1.1089e+00,\n",
      "         8.6623e-01, -1.9802e+00,  6.2010e-01,  1.7667e-01,  2.1189e+00,\n",
      "         9.9208e-02,  7.6328e-02,  7.0131e-02, -5.5222e-01,  1.8985e-01,\n",
      "         7.1685e-02,  2.3745e+00,  2.5768e-01, -1.3178e+00, -1.3817e+00,\n",
      "         3.1205e-01,  2.4576e+00, -3.1123e+00, -6.6158e+00,  2.4462e+00,\n",
      "         7.7643e+00, -1.2884e+00, -3.5947e+00, -9.7494e+00, -1.9851e+00,\n",
      "         2.5130e-03, -2.5624e-02,  1.7715e-01, -1.8103e+00,  4.6047e-01,\n",
      "        -5.3285e-01, -5.0640e-01,  1.7158e+00,  4.4128e-02,  7.2217e-01,\n",
      "        -6.1605e-01,  2.7272e-01, -8.2481e-01,  8.8195e-01, -1.7563e-01,\n",
      "         8.5709e-02, -2.4292e+00, -1.1119e+00,  5.2113e-01, -1.6877e+00,\n",
      "        -3.5572e+00, -1.8885e+00,  3.3218e+00,  8.8854e+00,  9.2087e-01,\n",
      "        -2.7637e-01,  5.3560e-03,  6.5158e-01,  1.6268e+00,  5.0904e+00,\n",
      "         7.0358e+00,  1.8726e+01,  2.5527e+01,  6.3484e+01,  2.0395e+02,\n",
      "         1.1798e+01, -2.1670e+00, -9.8126e-01,  3.9491e-01, -8.3600e-01,\n",
      "        -2.5793e-01, -1.6342e+00, -1.8709e+00,  7.7943e-01, -2.3963e-01,\n",
      "        -5.0043e-01,  5.3257e-01, -8.4200e-02,  1.1839e+00, -2.5782e-03,\n",
      "         3.1275e-02, -2.8015e-02,  1.1792e-01,  1.9702e+00, -1.7070e-01,\n",
      "         2.2983e-01,  5.0551e-02,  5.7895e-02, -5.0973e-01,  3.9192e-01,\n",
      "         3.5754e-02, -8.1265e-01, -1.7436e+00, -1.3218e+00, -8.3320e-01,\n",
      "        -3.3767e-01, -1.9486e+00, -4.0663e+00, -5.7412e+00, -1.2843e+01,\n",
      "        -7.5738e+00, -5.9771e+00, -9.7881e-01, -1.6632e-01,  2.2874e-01,\n",
      "        -1.3541e-01, -6.3850e-01, -1.1227e+00,  3.2603e-01, -2.1402e+00,\n",
      "        -8.0038e-01, -1.3604e+00, -6.9861e-01,  3.7713e-01,  1.6482e+00,\n",
      "         1.0219e+00,  4.4011e+00,  1.7541e+00, -1.3339e+00, -3.2970e-01,\n",
      "        -7.2139e-02,  1.0673e+00,  1.3049e+00,  3.3793e-01, -1.0100e+00,\n",
      "        -6.7461e-01, -6.7253e-02, -6.0554e-01, -4.7529e-01, -5.6684e-01,\n",
      "        -1.9111e+00,  1.4626e-01,  1.0448e+00, -1.8863e+00, -1.4126e+00,\n",
      "        -1.3160e+01, -1.4341e+00, -2.8362e-01, -2.7976e-03, -1.6893e+00,\n",
      "        -8.4646e-02,  1.0408e-01,  1.2607e-01, -5.1398e-02, -6.6682e-02,\n",
      "         2.9505e+00, -1.3118e-01, -9.5984e-01,  3.2471e+00, -1.9435e+00,\n",
      "         5.2979e-01,  1.2568e-01,  2.7429e+00,  2.6580e+00,  9.9367e+00,\n",
      "         2.1221e+01,  6.3428e+00, -1.5898e+00,  3.5454e+00,  9.1949e-01,\n",
      "         9.2343e-01,  4.7109e-01, -2.1598e+00, -4.8293e+00, -7.6606e+00,\n",
      "        -1.4053e+00,  1.0853e-01, -8.3476e-01, -7.8699e-01,  2.2439e-01,\n",
      "        -1.3758e+00, -6.3201e-02, -1.3846e-01,  7.3984e-01, -5.1305e-02,\n",
      "        -6.3696e-01,  1.5326e+00,  7.0233e-01,  1.0965e+00, -1.2028e+00,\n",
      "        -6.3058e-02,  7.5767e-01, -2.0036e-01, -4.0356e-01, -9.3448e-02,\n",
      "        -9.3196e-02,  1.8061e+00,  2.5725e+00, -2.4424e+00, -3.2516e+00,\n",
      "         1.0277e+00, -6.5928e-01, -1.1092e-01,  4.1812e-01,  7.8748e-02,\n",
      "        -2.4212e-01, -2.3400e-01, -4.5191e-01, -4.8019e-01,  6.6138e-03,\n",
      "         1.8965e+00, -5.5563e-01, -4.5679e-02,  1.2768e+00,  5.1737e-01,\n",
      "         1.7294e-01, -9.9629e-01, -1.2001e+00,  9.0683e-01, -1.0055e+00,\n",
      "         1.7277e+00, -1.2483e+00,  2.6060e+00,  8.1140e-01, -5.3431e-01,\n",
      "         1.0987e-01, -3.7811e-01,  1.5116e-01,  7.6353e-01,  7.3390e-01,\n",
      "        -7.4091e-01,  1.0573e-01, -1.5229e+00,  8.8817e-01,  4.0068e-01,\n",
      "         5.4434e-02, -1.4697e-01, -9.2226e-01,  5.9408e-01, -1.5866e+00,\n",
      "        -9.9976e-01,  5.3210e-01,  5.1079e+00,  2.3217e+00, -9.5937e-01,\n",
      "        -1.0449e+00, -5.9642e-02, -9.4447e-01, -6.0930e-02, -1.5606e-03,\n",
      "         3.3856e-01, -2.0147e-01, -3.2085e-02, -6.1327e-01,  8.1603e-01,\n",
      "        -4.8132e-01,  1.6937e-02,  4.0072e-01,  1.1127e-02, -3.8012e-01,\n",
      "        -7.2514e-02,  3.9677e-02, -1.0136e+00, -6.6903e-01,  7.5105e-01,\n",
      "        -2.9188e-01,  2.4665e-01,  2.0332e-01, -3.6907e-03, -1.1124e-01,\n",
      "        -1.0360e+00, -1.8011e+00,  8.9210e-02,  2.0088e-01, -1.0140e+00,\n",
      "         8.5565e-02, -2.0650e+00, -2.1703e-01, -8.0869e-01, -1.9944e+00,\n",
      "        -1.1282e+00, -1.7014e+00, -1.3950e-01,  3.9701e+00, -7.0574e-01,\n",
      "         9.2351e-01, -5.8526e-01, -4.1785e-01, -1.1223e+00,  1.5395e-01,\n",
      "         1.6811e-01,  1.3703e-01,  1.5979e-01, -1.0918e-01,  4.5418e-01,\n",
      "         1.0875e+00, -1.8294e-01,  6.6369e-01,  3.1302e-01, -4.6684e-01,\n",
      "        -5.2256e-02,  1.5229e+00, -2.4131e-01,  7.5324e-02,  6.8657e-03,\n",
      "         4.2367e-01, -2.8502e-02,  1.7256e+00, -1.5071e-01, -7.9524e-01,\n",
      "        -1.5472e+00, -1.6130e-01, -1.1590e+00, -3.1340e+00, -2.3238e-01,\n",
      "        -2.8238e+00,  3.2715e-01, -4.6422e-01,  1.5776e-01, -7.0881e-01,\n",
      "         2.7196e-02,  5.5997e-01,  5.3145e-02,  1.0719e+00, -2.3673e-01,\n",
      "         2.2812e-01, -5.5729e-01, -4.8402e-02,  1.3898e-01,  1.8775e-02,\n",
      "        -1.4202e-01, -6.7946e-01, -1.1837e-01, -2.2454e-01, -4.6413e-01,\n",
      "        -1.6209e+00, -1.2696e+00, -1.6505e-01,  2.3820e+00, -1.2942e+00],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 1.9724e+00],\n",
      "        [-9.5479e-01],\n",
      "        [ 1.6394e+00],\n",
      "        [-1.1876e+00],\n",
      "        [-6.8182e-01],\n",
      "        [ 1.9104e-01],\n",
      "        [ 1.1763e-01],\n",
      "        [ 1.8750e-01],\n",
      "        [ 1.8298e+00],\n",
      "        [ 4.8295e-01],\n",
      "        [-1.0284e+00],\n",
      "        [-1.2670e-01],\n",
      "        [-1.0294e+00],\n",
      "        [ 1.0028e+00],\n",
      "        [ 5.6268e-02],\n",
      "        [-7.1770e-02],\n",
      "        [-9.9067e-01],\n",
      "        [-7.7688e-01],\n",
      "        [ 9.7280e-01],\n",
      "        [ 9.9374e-01],\n",
      "        [-6.9495e-01],\n",
      "        [-7.1496e-01],\n",
      "        [-1.2089e+00],\n",
      "        [-5.8985e-01],\n",
      "        [-1.0980e+00],\n",
      "        [-1.0898e+00],\n",
      "        [ 2.6137e+00],\n",
      "        [ 1.1394e-01],\n",
      "        [ 1.6408e+00],\n",
      "        [ 7.5216e-01],\n",
      "        [ 8.6058e-01],\n",
      "        [ 4.6925e-01],\n",
      "        [-4.6040e-01],\n",
      "        [ 1.0673e-01],\n",
      "        [-1.1996e+00],\n",
      "        [ 1.6181e+00],\n",
      "        [ 3.8140e-01],\n",
      "        [-7.2776e-01],\n",
      "        [-1.2011e+00],\n",
      "        [ 2.7500e-01],\n",
      "        [-2.5305e-01],\n",
      "        [-6.0384e-01],\n",
      "        [-2.7971e-01],\n",
      "        [-7.3450e-01],\n",
      "        [-7.2499e-01],\n",
      "        [-1.2910e+00],\n",
      "        [ 9.4596e-03],\n",
      "        [-1.2887e+00],\n",
      "        [-1.2171e+00],\n",
      "        [-8.9700e-01],\n",
      "        [-2.9016e-01],\n",
      "        [-8.3825e-01],\n",
      "        [-1.0184e+00],\n",
      "        [-8.0986e-01],\n",
      "        [-2.8333e-01],\n",
      "        [-3.4107e-01],\n",
      "        [-4.4631e-01],\n",
      "        [-6.3566e-01],\n",
      "        [ 1.8838e+00],\n",
      "        [ 3.2128e-01],\n",
      "        [-1.2887e+00],\n",
      "        [-2.3821e-02],\n",
      "        [-1.5727e-01],\n",
      "        [-3.4106e-01],\n",
      "        [-4.8251e-01],\n",
      "        [ 1.3492e+00],\n",
      "        [-8.0858e-01],\n",
      "        [-9.6242e-02],\n",
      "        [ 2.1438e-01],\n",
      "        [ 1.6770e+00],\n",
      "        [-9.6052e-01],\n",
      "        [ 1.2371e+00],\n",
      "        [ 2.1980e+00],\n",
      "        [-4.4795e-02],\n",
      "        [-6.6225e-01],\n",
      "        [ 9.9572e-01],\n",
      "        [-5.0077e-01],\n",
      "        [-4.8101e-01],\n",
      "        [ 2.2894e+00],\n",
      "        [ 5.9155e-01],\n",
      "        [ 2.4337e-01],\n",
      "        [-5.6957e-01],\n",
      "        [ 1.4802e+00],\n",
      "        [-1.2985e+00],\n",
      "        [-1.2887e+00],\n",
      "        [-5.1264e-01],\n",
      "        [-6.4536e-01],\n",
      "        [ 2.2236e-01],\n",
      "        [-8.6952e-01],\n",
      "        [-1.4981e-02],\n",
      "        [-1.1160e+00],\n",
      "        [ 3.1374e-01],\n",
      "        [-1.2985e+00],\n",
      "        [-8.3199e-01],\n",
      "        [-1.2887e+00],\n",
      "        [-4.1172e-01],\n",
      "        [ 1.5813e-01],\n",
      "        [ 1.7040e+00],\n",
      "        [ 2.9648e-01],\n",
      "        [-4.1853e-01],\n",
      "        [ 2.8147e-01],\n",
      "        [-8.6495e-01],\n",
      "        [-8.0260e-01],\n",
      "        [ 2.1075e-01],\n",
      "        [-1.1981e+00],\n",
      "        [-8.0414e-01],\n",
      "        [ 1.8458e+00],\n",
      "        [ 2.0688e+00],\n",
      "        [-1.1539e+00],\n",
      "        [-3.9945e-01],\n",
      "        [-7.8848e-01],\n",
      "        [-1.1283e+00],\n",
      "        [ 1.8588e-01],\n",
      "        [ 2.8931e-01],\n",
      "        [-1.1885e+00],\n",
      "        [-8.0678e-01],\n",
      "        [ 1.5536e+00],\n",
      "        [-9.7705e-01],\n",
      "        [-7.0382e-01],\n",
      "        [-1.2882e-02],\n",
      "        [-1.0965e+00],\n",
      "        [-4.1855e-01],\n",
      "        [-1.1159e+00],\n",
      "        [-1.1363e+00],\n",
      "        [ 1.3414e+00],\n",
      "        [-1.1895e+00],\n",
      "        [ 2.9092e-01],\n",
      "        [ 2.1813e-01],\n",
      "        [ 2.4964e-01],\n",
      "        [-6.7025e-02],\n",
      "        [ 2.4538e-01],\n",
      "        [ 3.3479e-01],\n",
      "        [-9.3423e-01],\n",
      "        [-1.1249e-01],\n",
      "        [ 4.0066e-02],\n",
      "        [ 5.3261e-01],\n",
      "        [-4.7401e-01],\n",
      "        [-1.2888e+00],\n",
      "        [ 1.9983e+00],\n",
      "        [ 3.4616e-01],\n",
      "        [ 1.9458e+00],\n",
      "        [-1.2293e+00],\n",
      "        [-4.1100e-01],\n",
      "        [ 5.7875e-01],\n",
      "        [ 1.9227e+00],\n",
      "        [-1.2195e+00],\n",
      "        [-5.0715e-01],\n",
      "        [ 8.3379e-02],\n",
      "        [ 1.1035e+00],\n",
      "        [-8.5671e-01],\n",
      "        [-5.9471e-01],\n",
      "        [-1.4295e-01],\n",
      "        [-4.2542e-01],\n",
      "        [-7.1632e-01],\n",
      "        [-9.3071e-01],\n",
      "        [-1.2978e+00],\n",
      "        [ 5.5715e-01],\n",
      "        [-1.0907e+00],\n",
      "        [ 2.0324e+00],\n",
      "        [ 4.4938e-03],\n",
      "        [ 6.1510e-01],\n",
      "        [ 2.5899e-02],\n",
      "        [-1.1972e+00],\n",
      "        [ 1.7301e+00],\n",
      "        [ 2.8680e-02],\n",
      "        [-2.4334e-01],\n",
      "        [-1.2088e+00],\n",
      "        [-1.0452e+00],\n",
      "        [ 4.9121e-01],\n",
      "        [-9.3303e-01],\n",
      "        [-7.4665e-01],\n",
      "        [-1.2966e+00],\n",
      "        [-1.2976e-02],\n",
      "        [-2.4485e-01],\n",
      "        [ 8.2869e-01],\n",
      "        [ 7.8524e-02],\n",
      "        [ 4.7594e-01],\n",
      "        [-4.0993e-01],\n",
      "        [-9.3854e-02],\n",
      "        [ 4.1411e-01],\n",
      "        [-1.2276e+00],\n",
      "        [-1.0561e+00],\n",
      "        [ 2.1094e+00],\n",
      "        [-5.6468e-01],\n",
      "        [-4.8051e-01],\n",
      "        [ 2.5074e+00],\n",
      "        [-6.6196e-01],\n",
      "        [-2.1554e-01],\n",
      "        [-8.7568e-01],\n",
      "        [-1.1899e+00],\n",
      "        [ 4.3264e-01],\n",
      "        [-1.4164e-01],\n",
      "        [-1.8626e-01],\n",
      "        [-4.0302e-01],\n",
      "        [ 1.7927e+00],\n",
      "        [ 1.9311e-02],\n",
      "        [-1.0265e+00],\n",
      "        [-9.0809e-01],\n",
      "        [-1.2887e+00],\n",
      "        [ 1.0743e+00],\n",
      "        [ 6.5018e-02],\n",
      "        [-2.5470e-01],\n",
      "        [-5.5417e-01],\n",
      "        [-5.3881e-01],\n",
      "        [-9.5112e-01],\n",
      "        [-4.4417e-01],\n",
      "        [-7.7782e-01],\n",
      "        [-1.0026e+00],\n",
      "        [-6.2191e-01],\n",
      "        [-4.6002e-01],\n",
      "        [ 1.9426e-01],\n",
      "        [-2.3482e-01],\n",
      "        [-4.6923e-01],\n",
      "        [ 2.0273e+00],\n",
      "        [ 1.0807e+00],\n",
      "        [-4.9743e-01],\n",
      "        [-1.1402e+00],\n",
      "        [ 3.9106e+00],\n",
      "        [ 1.8305e+00],\n",
      "        [-9.1352e-01],\n",
      "        [ 1.5133e-01],\n",
      "        [-2.7187e-01],\n",
      "        [ 1.2968e+00],\n",
      "        [-8.9577e-01],\n",
      "        [-9.8636e-01],\n",
      "        [ 1.7905e+00],\n",
      "        [-4.5921e-01],\n",
      "        [-1.8060e-02],\n",
      "        [ 7.9397e-01],\n",
      "        [ 1.7551e+00],\n",
      "        [ 2.0852e+00],\n",
      "        [ 1.2664e-01],\n",
      "        [-6.4861e-01],\n",
      "        [-1.0671e+00],\n",
      "        [ 2.6879e+00],\n",
      "        [-9.0527e-01],\n",
      "        [ 6.8031e-01],\n",
      "        [-1.0086e+00],\n",
      "        [-3.4292e-01],\n",
      "        [ 6.4372e-02],\n",
      "        [-1.8741e-01],\n",
      "        [ 8.0757e-02],\n",
      "        [ 1.9384e+00],\n",
      "        [-8.9689e-01],\n",
      "        [ 7.6064e-02],\n",
      "        [-1.2938e+00],\n",
      "        [ 5.3641e-01],\n",
      "        [ 5.6394e-01],\n",
      "        [ 2.9546e-01],\n",
      "        [ 1.2726e+00],\n",
      "        [-1.1874e+00],\n",
      "        [ 1.7193e+00],\n",
      "        [-5.3699e-01],\n",
      "        [-1.1675e+00],\n",
      "        [-2.2233e-01],\n",
      "        [ 4.6265e-01],\n",
      "        [-3.4334e-02],\n",
      "        [-4.5436e-01],\n",
      "        [ 6.1384e-01],\n",
      "        [-9.3185e-01],\n",
      "        [ 4.0378e-01],\n",
      "        [-2.9885e-01],\n",
      "        [-1.2008e+00],\n",
      "        [ 1.7784e+00],\n",
      "        [ 9.9718e-01],\n",
      "        [-6.9331e-01],\n",
      "        [-7.6910e-02],\n",
      "        [-1.1586e+00],\n",
      "        [-1.0014e+00],\n",
      "        [ 2.2014e-01],\n",
      "        [-7.1338e-01],\n",
      "        [-9.2284e-01],\n",
      "        [ 8.0252e-01],\n",
      "        [-7.8470e-01],\n",
      "        [-6.6796e-01],\n",
      "        [-1.0521e+00],\n",
      "        [ 3.6483e-01],\n",
      "        [ 4.2816e-01],\n",
      "        [-6.0230e-02],\n",
      "        [-1.2928e+00],\n",
      "        [ 4.5678e-01],\n",
      "        [-1.2572e-01],\n",
      "        [-1.2288e+00],\n",
      "        [ 3.7810e+00],\n",
      "        [-5.6665e-01],\n",
      "        [ 8.2431e-01],\n",
      "        [-9.6573e-01],\n",
      "        [-3.2170e-01],\n",
      "        [ 7.4801e-01],\n",
      "        [-1.4066e-01],\n",
      "        [ 5.1969e-02],\n",
      "        [ 1.1583e-01],\n",
      "        [-7.8054e-01],\n",
      "        [ 1.9619e+00],\n",
      "        [-4.4008e-01],\n",
      "        [ 3.8502e-02],\n",
      "        [-8.4811e-02],\n",
      "        [ 8.1991e-01],\n",
      "        [ 3.6869e-01],\n",
      "        [ 4.3492e-01],\n",
      "        [-6.8282e-01],\n",
      "        [ 2.3676e+00],\n",
      "        [-1.2852e-01],\n",
      "        [-1.2093e+00],\n",
      "        [-3.4905e-01],\n",
      "        [-1.9039e-01],\n",
      "        [ 8.5496e-02],\n",
      "        [ 1.9768e-01],\n",
      "        [-3.6413e-01],\n",
      "        [-1.0906e+00],\n",
      "        [-6.0136e-01],\n",
      "        [-2.6335e-02],\n",
      "        [-1.0900e+00],\n",
      "        [ 5.4888e-02],\n",
      "        [-3.6228e-01],\n",
      "        [-5.2990e-01],\n",
      "        [ 9.6638e-01],\n",
      "        [-1.2158e+00],\n",
      "        [ 1.3533e-01],\n",
      "        [ 1.8127e-01],\n",
      "        [-1.1994e+00],\n",
      "        [-9.9489e-01],\n",
      "        [-4.6511e-01],\n",
      "        [-7.6833e-02],\n",
      "        [-1.1291e+00],\n",
      "        [-3.2451e-01],\n",
      "        [ 4.7484e-01],\n",
      "        [ 4.5385e-02],\n",
      "        [-9.7748e-01],\n",
      "        [-2.2298e-01],\n",
      "        [ 1.8297e+00],\n",
      "        [-1.1591e+00],\n",
      "        [-1.1479e+00],\n",
      "        [-1.4893e-01],\n",
      "        [ 1.4134e-01],\n",
      "        [ 2.1831e+00],\n",
      "        [-3.1230e-01],\n",
      "        [-1.2052e+00],\n",
      "        [-8.5274e-01],\n",
      "        [-3.9516e-01],\n",
      "        [-1.2970e+00],\n",
      "        [ 1.6398e+00],\n",
      "        [-6.6463e-01],\n",
      "        [ 1.3729e+00],\n",
      "        [ 1.5559e-01],\n",
      "        [-5.6762e-01],\n",
      "        [-6.5801e-01],\n",
      "        [-7.8806e-01],\n",
      "        [-3.1988e-01],\n",
      "        [ 1.3361e+00],\n",
      "        [ 3.8728e-01],\n",
      "        [-5.8796e-01],\n",
      "        [-8.1465e-01],\n",
      "        [-5.1842e-01],\n",
      "        [ 1.1315e+00],\n",
      "        [ 2.0803e+00],\n",
      "        [-7.5076e-01],\n",
      "        [ 3.1383e+00],\n",
      "        [-6.0215e-01],\n",
      "        [ 2.3822e+00],\n",
      "        [-6.6953e-01],\n",
      "        [ 2.3189e-02],\n",
      "        [-6.4441e-01],\n",
      "        [ 1.9668e+00],\n",
      "        [-6.2910e-01],\n",
      "        [ 4.7382e-01],\n",
      "        [-7.8185e-01],\n",
      "        [-1.2905e+00],\n",
      "        [ 1.8918e-01],\n",
      "        [-8.5448e-01],\n",
      "        [-3.0478e-01],\n",
      "        [-9.7684e-01],\n",
      "        [-1.0281e+00],\n",
      "        [-5.7912e-01],\n",
      "        [-5.9273e-01],\n",
      "        [-4.0754e-01],\n",
      "        [-4.8399e-01],\n",
      "        [ 1.9249e-01],\n",
      "        [ 2.1485e-01],\n",
      "        [ 1.4526e+00],\n",
      "        [-8.7079e-01],\n",
      "        [ 1.4549e+00],\n",
      "        [-3.3841e-01],\n",
      "        [ 2.8430e-01],\n",
      "        [-3.9596e-01],\n",
      "        [ 2.2185e-01],\n",
      "        [ 3.2740e-01],\n",
      "        [ 1.6990e-01],\n",
      "        [-1.2887e+00],\n",
      "        [ 1.4092e+00],\n",
      "        [-1.2887e+00],\n",
      "        [ 4.8778e-01],\n",
      "        [ 5.8715e-02],\n",
      "        [-1.2948e+00],\n",
      "        [ 1.4781e+00],\n",
      "        [-7.8659e-01],\n",
      "        [-3.9184e-01],\n",
      "        [ 6.4192e-02],\n",
      "        [ 6.7152e-01],\n",
      "        [-1.2063e+00],\n",
      "        [ 1.3321e+00],\n",
      "        [ 1.5473e-03],\n",
      "        [ 1.7541e+00],\n",
      "        [ 4.6174e-01],\n",
      "        [-5.8222e-01],\n",
      "        [-1.2887e+00],\n",
      "        [ 1.3653e+00],\n",
      "        [ 1.8508e-01],\n",
      "        [ 8.8033e-01],\n",
      "        [ 1.8225e+00],\n",
      "        [ 3.7050e-02],\n",
      "        [ 6.3315e-01],\n",
      "        [-5.8990e-01],\n",
      "        [-1.0948e+00],\n",
      "        [ 3.6213e-01],\n",
      "        [-6.0815e-01],\n",
      "        [-9.8724e-01],\n",
      "        [ 2.1014e+00],\n",
      "        [-1.2887e+00],\n",
      "        [ 1.4312e+00],\n",
      "        [-1.1035e+00],\n",
      "        [-1.2025e+00],\n",
      "        [-1.0646e+00],\n",
      "        [ 4.4272e-01],\n",
      "        [ 1.4110e-01],\n",
      "        [ 1.1017e-01],\n",
      "        [-5.0705e-02],\n",
      "        [-8.2115e-01],\n",
      "        [ 2.1814e-01],\n",
      "        [-3.9874e-01],\n",
      "        [ 1.9140e+00],\n",
      "        [ 1.0764e+00],\n",
      "        [-6.7323e-01],\n",
      "        [ 1.6323e-01],\n",
      "        [ 2.0671e+00],\n",
      "        [ 3.6222e+00],\n",
      "        [-2.6275e-01],\n",
      "        [-3.2471e-02],\n",
      "        [-9.8535e-01],\n",
      "        [ 1.2420e+00],\n",
      "        [ 5.7513e-02],\n",
      "        [ 1.5385e+00],\n",
      "        [-4.6330e-01],\n",
      "        [-4.4375e-01],\n",
      "        [ 5.6601e-01],\n",
      "        [ 1.5092e+00],\n",
      "        [ 1.4378e+00],\n",
      "        [-7.2925e-01],\n",
      "        [ 2.7478e-01],\n",
      "        [ 2.1559e-02],\n",
      "        [ 4.1216e-01],\n",
      "        [ 3.2910e+00],\n",
      "        [ 9.0753e-01],\n",
      "        [-1.4408e-01],\n",
      "        [-1.2304e+00],\n",
      "        [ 3.3292e-01],\n",
      "        [-8.2586e-01],\n",
      "        [ 7.1180e-01],\n",
      "        [-4.1080e-01],\n",
      "        [ 1.0692e+00],\n",
      "        [-1.2106e+00],\n",
      "        [-1.1959e+00],\n",
      "        [ 1.4411e+00],\n",
      "        [-6.1806e-01],\n",
      "        [-5.8810e-01],\n",
      "        [-2.5179e-01],\n",
      "        [-8.9837e-01],\n",
      "        [ 1.0771e+00],\n",
      "        [-8.1867e-01],\n",
      "        [ 5.2236e-02],\n",
      "        [-2.2708e-01],\n",
      "        [ 4.7795e-01],\n",
      "        [ 8.0612e-01],\n",
      "        [ 4.8182e-01],\n",
      "        [-6.0860e-01],\n",
      "        [-6.6769e-01],\n",
      "        [-1.1428e+00],\n",
      "        [ 2.4367e-01],\n",
      "        [-7.8115e-01],\n",
      "        [-1.2933e+00],\n",
      "        [-4.9570e-01],\n",
      "        [ 4.7019e-01],\n",
      "        [-1.0901e+00],\n",
      "        [-1.2979e+00],\n",
      "        [-8.5232e-01],\n",
      "        [-1.1435e+00],\n",
      "        [ 2.1176e-01],\n",
      "        [-1.0261e+00],\n",
      "        [-1.2925e+00],\n",
      "        [-7.3905e-01],\n",
      "        [ 9.2560e-01],\n",
      "        [ 3.9361e-01],\n",
      "        [ 1.3720e+00],\n",
      "        [-7.3920e-01],\n",
      "        [-1.2059e+00],\n",
      "        [-1.2894e+00],\n",
      "        [-1.0678e+00],\n",
      "        [ 6.7139e-01],\n",
      "        [-7.4233e-01],\n",
      "        [ 5.2805e-01],\n",
      "        [ 1.7185e-01],\n",
      "        [-1.9782e-01],\n",
      "        [-8.4178e-01],\n",
      "        [ 4.4423e-01],\n",
      "        [ 1.6170e-01],\n",
      "        [-9.3272e-01],\n",
      "        [-1.1114e+00],\n",
      "        [ 1.4757e+00],\n",
      "        [-3.2961e-01],\n",
      "        [ 3.2400e-01],\n",
      "        [ 1.7661e-01],\n",
      "        [ 1.4504e+00],\n",
      "        [ 2.1832e+00],\n",
      "        [-2.9979e-01],\n",
      "        [-1.1996e+00],\n",
      "        [ 5.8531e-01],\n",
      "        [-1.1079e+00],\n",
      "        [-1.2972e+00],\n",
      "        [-2.3779e-01],\n",
      "        [-3.2722e-01],\n",
      "        [-9.3356e-01],\n",
      "        [-4.6905e-01],\n",
      "        [ 1.8678e+00],\n",
      "        [-1.1969e+00],\n",
      "        [-3.8541e-01],\n",
      "        [ 2.1254e+00],\n",
      "        [-1.0172e+00],\n",
      "        [ 6.9580e-01],\n",
      "        [-8.8685e-01],\n",
      "        [-1.1936e+00],\n",
      "        [ 1.1059e+00],\n",
      "        [-1.0341e+00],\n",
      "        [-3.5409e-01],\n",
      "        [-1.2020e+00],\n",
      "        [-1.1599e+00],\n",
      "        [-4.3438e-02],\n",
      "        [-1.1447e+00],\n",
      "        [-7.6595e-01],\n",
      "        [-1.2909e+00],\n",
      "        [-7.7953e-02],\n",
      "        [ 8.2488e-01],\n",
      "        [ 9.2239e-01],\n",
      "        [-1.9282e-01],\n",
      "        [ 1.3605e-01],\n",
      "        [-1.2197e+00],\n",
      "        [-1.0933e+00],\n",
      "        [-2.4384e-01],\n",
      "        [ 5.9578e-02],\n",
      "        [ 2.4496e+00],\n",
      "        [ 2.6290e-01],\n",
      "        [-4.4860e-01],\n",
      "        [-4.4944e-02],\n",
      "        [ 6.4111e-01],\n",
      "        [-3.1911e-01],\n",
      "        [-2.2952e-01],\n",
      "        [ 3.8440e-02],\n",
      "        [ 3.6031e-02],\n",
      "        [-6.7566e-01],\n",
      "        [-6.0217e-01],\n",
      "        [ 2.4698e+00],\n",
      "        [-1.0967e+00],\n",
      "        [-1.1441e+00],\n",
      "        [ 4.0162e+00],\n",
      "        [ 2.8635e-01],\n",
      "        [ 4.2019e-01],\n",
      "        [ 9.7039e-01],\n",
      "        [ 2.4256e+00],\n",
      "        [-4.5066e-01],\n",
      "        [ 3.0096e+00],\n",
      "        [ 3.9098e-01],\n",
      "        [-1.1951e+00],\n",
      "        [-1.1667e+00],\n",
      "        [-9.5435e-01],\n",
      "        [ 1.4532e+00],\n",
      "        [-1.1090e-01],\n",
      "        [-5.6567e-01],\n",
      "        [-5.6139e-01],\n",
      "        [-5.1914e-01],\n",
      "        [ 1.1018e+00],\n",
      "        [ 1.4587e+00],\n",
      "        [ 1.0871e+00],\n",
      "        [ 7.3622e-01],\n",
      "        [-3.8288e-01],\n",
      "        [ 1.5977e+00],\n",
      "        [ 1.4488e-01],\n",
      "        [-4.5713e-01],\n",
      "        [-3.0638e-01],\n",
      "        [ 7.5523e-01],\n",
      "        [-1.0207e+00],\n",
      "        [-1.0649e+00],\n",
      "        [ 1.7688e+00],\n",
      "        [ 2.4897e-01],\n",
      "        [ 1.8629e+00],\n",
      "        [-8.7813e-01],\n",
      "        [ 4.8706e-01],\n",
      "        [ 2.1166e+00],\n",
      "        [-1.2887e+00],\n",
      "        [-1.1018e+00],\n",
      "        [-4.5163e-01],\n",
      "        [-4.9723e-01],\n",
      "        [ 1.7373e+00],\n",
      "        [ 7.3397e-01],\n",
      "        [-1.2887e+00],\n",
      "        [-1.2887e+00],\n",
      "        [ 5.2398e-01],\n",
      "        [-4.8295e-01],\n",
      "        [-7.1756e-01],\n",
      "        [ 9.5196e-01],\n",
      "        [ 1.3172e-01],\n",
      "        [-7.4074e-01],\n",
      "        [-9.7185e-01],\n",
      "        [-9.7348e-01],\n",
      "        [-1.2217e+00],\n",
      "        [-3.0909e-01],\n",
      "        [ 2.1572e+00],\n",
      "        [-9.5182e-01],\n",
      "        [ 2.3158e-01],\n",
      "        [ 1.7504e+00],\n",
      "        [-7.3220e-01],\n",
      "        [ 8.5081e-01],\n",
      "        [-5.6271e-01],\n",
      "        [ 1.6151e-01],\n",
      "        [ 2.6958e-01],\n",
      "        [-1.2891e+00],\n",
      "        [ 1.9043e+00],\n",
      "        [-1.2320e+00],\n",
      "        [ 2.2765e+00],\n",
      "        [-1.0409e+00],\n",
      "        [-1.3574e-01],\n",
      "        [-1.2292e-01],\n",
      "        [-5.4872e-01],\n",
      "        [ 2.1285e-01],\n",
      "        [ 1.0720e+00],\n",
      "        [ 1.4585e+00],\n",
      "        [-6.4375e-01],\n",
      "        [ 6.1423e-01],\n",
      "        [-6.2503e-01],\n",
      "        [ 8.5630e-01],\n",
      "        [ 5.9509e-02],\n",
      "        [-1.0804e-01],\n",
      "        [-2.7349e-01],\n",
      "        [-8.1493e-01],\n",
      "        [ 2.4083e+00],\n",
      "        [-5.1158e-01],\n",
      "        [-2.3108e-01],\n",
      "        [-6.5278e-01],\n",
      "        [ 3.3448e+00],\n",
      "        [-5.8182e-01],\n",
      "        [-2.5671e-01],\n",
      "        [-8.6376e-01],\n",
      "        [ 1.3620e+00],\n",
      "        [ 1.7523e+00],\n",
      "        [ 2.5203e-01],\n",
      "        [ 3.2921e-01],\n",
      "        [ 7.3023e-01],\n",
      "        [-2.6689e-01],\n",
      "        [ 1.1584e-01],\n",
      "        [-2.8042e-01],\n",
      "        [ 1.7704e+00],\n",
      "        [ 3.1580e-01],\n",
      "        [-3.4189e-01],\n",
      "        [ 6.1054e-01],\n",
      "        [-1.5825e-01],\n",
      "        [-1.2887e+00],\n",
      "        [-6.2141e-01],\n",
      "        [-2.6147e-01],\n",
      "        [-1.2918e+00],\n",
      "        [-2.4222e-01],\n",
      "        [ 1.7057e+00],\n",
      "        [ 1.6278e-01],\n",
      "        [ 5.1960e-01],\n",
      "        [ 9.4509e-01],\n",
      "        [ 3.3802e-01],\n",
      "        [-9.7736e-02],\n",
      "        [-8.8693e-01],\n",
      "        [-6.1073e-01],\n",
      "        [-9.1769e-01],\n",
      "        [ 1.3176e+00],\n",
      "        [-7.4941e-02],\n",
      "        [ 1.7896e+00],\n",
      "        [-2.4292e-02],\n",
      "        [-8.1929e-01],\n",
      "        [-1.2887e+00],\n",
      "        [-1.2914e+00],\n",
      "        [ 1.0516e+00],\n",
      "        [-1.0952e+00],\n",
      "        [ 1.8410e+00],\n",
      "        [-8.0124e-01],\n",
      "        [-1.0705e+00],\n",
      "        [ 1.7512e+00],\n",
      "        [-5.5380e-01],\n",
      "        [-1.7622e-01],\n",
      "        [-1.2887e+00],\n",
      "        [ 2.9651e-01],\n",
      "        [ 5.3944e-01],\n",
      "        [-4.0462e-01],\n",
      "        [-5.7036e-01],\n",
      "        [-8.0165e-01],\n",
      "        [-6.9209e-02],\n",
      "        [ 2.4753e-01],\n",
      "        [-1.2318e+00],\n",
      "        [-9.0823e-01],\n",
      "        [-5.8914e-02],\n",
      "        [-1.2914e+00],\n",
      "        [-5.8029e-01],\n",
      "        [ 2.0924e+00],\n",
      "        [-5.9667e-01],\n",
      "        [-2.7055e-01],\n",
      "        [-5.0725e-01],\n",
      "        [-4.4032e-01],\n",
      "        [-1.2950e+00],\n",
      "        [ 5.1188e-01],\n",
      "        [-8.2024e-01],\n",
      "        [-1.2170e+00],\n",
      "        [-1.1059e+00],\n",
      "        [-3.3383e-01],\n",
      "        [-5.4840e-01],\n",
      "        [-4.7892e-01],\n",
      "        [ 2.5108e+00],\n",
      "        [-4.8298e-02],\n",
      "        [ 1.7995e+00],\n",
      "        [ 4.1491e-01],\n",
      "        [ 1.4041e+00],\n",
      "        [ 1.4251e+00],\n",
      "        [-1.1456e+00],\n",
      "        [-6.1668e-01],\n",
      "        [-1.0316e+00],\n",
      "        [ 3.8899e-02],\n",
      "        [-4.9443e-01],\n",
      "        [ 2.1804e-01],\n",
      "        [-1.1243e+00],\n",
      "        [-4.2366e-01],\n",
      "        [-6.3382e-01],\n",
      "        [-5.6012e-01],\n",
      "        [-7.0417e-01],\n",
      "        [-1.1219e+00],\n",
      "        [ 5.1413e-02],\n",
      "        [-4.2385e-01],\n",
      "        [-4.8987e-01],\n",
      "        [-9.3663e-01],\n",
      "        [ 1.3177e+00],\n",
      "        [-7.1456e-01],\n",
      "        [ 1.7164e+00],\n",
      "        [-8.2056e-01],\n",
      "        [-1.2945e+00]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1000 [00:32<8:58:17, 32.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 27567.753751663935, Test_loss: 5.00799389396395\n",
      "tensor([ 1.6452, -0.3929,  0.7395,  ..., -1.1252, -2.2504,  0.0276],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 1.6447],\n",
      "        [ 0.7148],\n",
      "        [-0.3737],\n",
      "        ...,\n",
      "        [-0.8372],\n",
      "        [ 2.0762],\n",
      "        [ 0.0281]])\n",
      "tensor([ 3.8743,  0.5409, 21.5030,  ...,  0.8763, -0.3110, -0.3222],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 3.8740],\n",
      "        [-0.7288],\n",
      "        [-0.3791],\n",
      "        ...,\n",
      "        [ 0.2093],\n",
      "        [ 1.1826],\n",
      "        [-0.3221]])\n",
      "tensor([-0.9266, -0.1466, -0.2341,  ...,  0.2093,  0.7938,  1.9221],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.9267],\n",
      "        [-1.0864],\n",
      "        [-0.8448],\n",
      "        ...,\n",
      "        [ 0.4524],\n",
      "        [ 0.5890],\n",
      "        [ 1.9244]])\n",
      "tensor([-0.0433,  0.0697, -0.5122,  ...,  2.6846,  0.1443, -0.8588],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.0441],\n",
      "        [-0.6046],\n",
      "        [ 0.6767],\n",
      "        ...,\n",
      "        [-1.2970],\n",
      "        [-0.6475],\n",
      "        [-0.8589]])\n",
      "tensor([-0.9501, -4.5963,  0.2873,  ..., -0.0434, -0.1686, -0.3772],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.9502],\n",
      "        [-0.7981],\n",
      "        [-0.8185],\n",
      "        ...,\n",
      "        [-0.9559],\n",
      "        [-0.6022],\n",
      "        [-0.3771]])\n",
      "tensor([  1.2143, -13.7957,  -0.2195,  ...,   0.3693,  -0.8489,  -1.2104],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 1.2097],\n",
      "        [-0.1391],\n",
      "        [ 0.6774],\n",
      "        ...,\n",
      "        [-1.1961],\n",
      "        [ 0.4662],\n",
      "        [-1.2106]])\n",
      "tensor([ 0.5481, -0.3249, -0.5210,  ..., -0.3471,  1.2165,  1.4641],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.5492],\n",
      "        [-0.2448],\n",
      "        [ 1.7989],\n",
      "        ...,\n",
      "        [ 1.0974],\n",
      "        [ 0.8314],\n",
      "        [ 1.4634]])\n",
      "tensor([-0.4548,  0.0050, -0.2002,  ..., -0.3688,  0.0340, -0.2038],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[-0.4549],\n",
      "        [-0.5855],\n",
      "        [-0.4230],\n",
      "        ...,\n",
      "        [ 2.2808],\n",
      "        [ 1.3424],\n",
      "        [-0.2036]])\n",
      "tensor([ 0.9405,  1.1527,  3.3622,  ..., -2.5330, -0.8149, -0.0581],\n",
      "       grad_fn=<LinalgSolveBackward0>)\n",
      "tensor([[ 0.9402],\n",
      "        [ 0.0918],\n",
      "        [-0.8609],\n",
      "        ...,\n",
      "        [ 1.2793],\n",
      "        [ 0.2168],\n",
      "        [-0.0578]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:45<12:30:30, 45.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-39d8c6b4e25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# torch.set_printoptions(profile=\"full\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplicit_diffusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b28c07ea937b>\u001b[0m in \u001b[0;36mimplicit_diffusion\u001b[0;34m(self, temp, mean, std)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        mean=0.0\n",
    "        std=1.0\n",
    "        mean = torch.tensor(mean).to(device)\n",
    "        std = torch.tensor(std).to(device)\n",
    "        temp_input = x[:,13] * std + mean\n",
    "        #print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "        print(pred)\n",
    "        print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            mean=0.0\n",
    "            std=1.0\n",
    "            mean = torch.tensor(mean).to(device)\n",
    "            std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] * std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Diffusivity: 9.859477536592607e-06\n",
      "Test Rmse of Temp: 0.7826148693716032\n",
      "L2 Error of Diffusivity: 0.4382787878287092\n",
      "L2 Error  of Temp: 0.053899259632144064\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Diffusivity: 1.407105732980103e-06\n",
      "Train Rmse of Temp: 0.06460328518966645\n",
      "L2 Error of Diffusivity: 0.06055042984845283\n",
      "L2 Error  of Temp: 0.005046837794778314\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.07829505e-05, 1.13460421e+01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
