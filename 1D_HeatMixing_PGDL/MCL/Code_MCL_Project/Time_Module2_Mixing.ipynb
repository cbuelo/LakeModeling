{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_total04</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106170</th>\n",
       "      <td>21</td>\n",
       "      <td>28.094995</td>\n",
       "      <td>952.008506</td>\n",
       "      <td>-72.970251</td>\n",
       "      <td>-73.622512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>1.701971</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.039837</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.039837</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.039837</td>\n",
       "      <td>7.039837</td>\n",
       "      <td>11.407</td>\n",
       "      <td>11.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106171</th>\n",
       "      <td>22</td>\n",
       "      <td>28.094995</td>\n",
       "      <td>952.008506</td>\n",
       "      <td>-72.970251</td>\n",
       "      <td>-73.622512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>1.701971</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.216154</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>6.216154</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.216154</td>\n",
       "      <td>6.216154</td>\n",
       "      <td>11.407</td>\n",
       "      <td>11.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106172</th>\n",
       "      <td>23</td>\n",
       "      <td>28.094995</td>\n",
       "      <td>952.008506</td>\n",
       "      <td>-72.970251</td>\n",
       "      <td>-73.622512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>1.701971</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.401328</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.401328</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.401328</td>\n",
       "      <td>5.401328</td>\n",
       "      <td>11.407</td>\n",
       "      <td>11.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106173</th>\n",
       "      <td>24</td>\n",
       "      <td>28.094995</td>\n",
       "      <td>952.008506</td>\n",
       "      <td>-72.970251</td>\n",
       "      <td>-73.622512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>1.701971</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.590689</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.590689</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.590689</td>\n",
       "      <td>4.590689</td>\n",
       "      <td>11.407</td>\n",
       "      <td>11.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106174</th>\n",
       "      <td>25</td>\n",
       "      <td>28.094995</td>\n",
       "      <td>952.008506</td>\n",
       "      <td>-72.970251</td>\n",
       "      <td>-73.622512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>1.701971</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.781912</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.781912</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.781912</td>\n",
       "      <td>3.781912</td>\n",
       "      <td>11.407</td>\n",
       "      <td>11.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106175 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1           2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2           3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3           4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4           5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "106170     21     28.094995     952.008506   -72.970251     -73.622512   \n",
       "106171     22     28.094995     952.008506   -72.970251     -73.622512   \n",
       "106172     23     28.094995     952.008506   -72.970251     -73.622512   \n",
       "106173     24     28.094995     952.008506   -72.970251     -73.622512   \n",
       "106174     25     28.094995     952.008506   -72.970251     -73.622512   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0          0.255324            1.085796   \n",
       "1                  0.0          0.255324            1.085796   \n",
       "2                  0.0          0.255324            1.085796   \n",
       "3                  0.0          0.255324            1.085796   \n",
       "4                  0.0          0.255324            1.085796   \n",
       "...                ...               ...                 ...   \n",
       "106170             0.0          0.543757            1.701971   \n",
       "106171             0.0          0.543757            1.701971   \n",
       "106172             0.0          0.543757            1.701971   \n",
       "106173             0.0          0.543757            1.701971   \n",
       "106174             0.0          0.543757            1.701971   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  temp_total04  buoyancy  \\\n",
       "0               0.002290  36000000.0  ...     11.570472  0.000000   \n",
       "1               0.002290  36000000.0  ...     11.570472  0.000000   \n",
       "2               0.002290  36000000.0  ...     11.575860  0.000271   \n",
       "3               0.002290  36000000.0  ...     11.393058  0.000278   \n",
       "4               0.002290  36000000.0  ...     11.130929  0.000185   \n",
       "...                  ...         ...  ...           ...       ...   \n",
       "106170          0.004728  36000000.0  ...      7.039837  0.000329   \n",
       "106171          0.004728  36000000.0  ...      6.216154  0.000227   \n",
       "106172          0.004728  36000000.0  ...      5.401328  0.000127   \n",
       "106173          0.004728  36000000.0  ...      4.590689  0.000026   \n",
       "106174          0.004728  36000000.0  ...      3.781912  0.000026   \n",
       "\n",
       "        diffusivity  temp_diff01  day_of_year  time_of_day  temp_mix02  \\\n",
       "0          0.000037    11.467275          155            1   11.545011   \n",
       "1          0.000037    11.627332          155            1   11.545011   \n",
       "2          0.000021    11.631393          155            1   11.631393   \n",
       "3          0.000021    11.393058          155            1   11.393058   \n",
       "4          0.000024    11.130929          155            1   11.130929   \n",
       "...             ...          ...          ...          ...         ...   \n",
       "106170     0.000019     7.039837          213           23    7.039837   \n",
       "106171     0.000022     6.216154          213           23    6.216154   \n",
       "106172     0.000029     5.401328          213           23    5.401328   \n",
       "106173     0.000037     4.590689          213           23    4.590689   \n",
       "106174     0.000037     3.781912          213           23    3.781912   \n",
       "\n",
       "        temp_conv03  obs_temp  input_obs  \n",
       "0         11.570472    16.409     16.350  \n",
       "1         11.570472    16.480     16.426  \n",
       "2         11.575860    16.130     16.088  \n",
       "3         11.393058    15.827     15.789  \n",
       "4         11.130929    16.270     16.240  \n",
       "...             ...       ...        ...  \n",
       "106170     7.039837    11.407     11.407  \n",
       "106171     6.216154    11.407     11.407  \n",
       "106172     5.401328    11.407     11.407  \n",
       "106173     4.590689    11.407     11.407  \n",
       "106174     3.781912    11.407     11.407  \n",
       "\n",
       "[106175 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 4247\n",
      "Number of training points: 63700\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'day_of_year', 'time_of_day', 'temp_diff01']\n",
    "output_columns = ['temp_mix02']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (63700, 6), X_test: (42475, 6)\n",
      "y_train: (63700, 1), y_test: (42475, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=6, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/1000 [00:00<15:18,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.21822415407569634, Test_loss: 0.033907136658117884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                            | 51/1000 [00:45<15:44,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 0.0001044598725817946, Test_loss: 0.00011346106839482673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 101/1000 [01:29<15:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 9.2112927314514e-05, Test_loss: 8.563183709633276e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▉                                                                   | 151/1000 [02:14<14:07,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 9.455968234212219e-05, Test_loss: 7.273201181522468e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▉                                                               | 201/1000 [03:00<13:53,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 9.156666558174904e-05, Test_loss: 6.797040740972686e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▊                                                           | 251/1000 [03:45<12:40,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 8.904838597074905e-05, Test_loss: 7.447338125963316e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▊                                                       | 301/1000 [04:30<12:16,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 9.065005863140825e-05, Test_loss: 7.489641042671533e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████▋                                                   | 351/1000 [05:15<10:59,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 8.891833328114386e-05, Test_loss: 7.483435897050921e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▋                                               | 401/1000 [06:07<17:35,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 9.145173894394824e-05, Test_loss: 7.974109989629055e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████▋                                           | 451/1000 [07:25<15:56,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 8.917054941458258e-05, Test_loss: 7.078930364167761e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▌                                       | 501/1000 [08:43<14:28,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 8.335423344472056e-05, Test_loss: 6.327131214740283e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▌                                   | 551/1000 [10:01<12:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 8.379785550272255e-05, Test_loss: 6.351877129873174e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▍                               | 601/1000 [11:18<11:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 8.264533404317695e-05, Test_loss: 6.26570505766094e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████▍                           | 651/1000 [12:36<10:20,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 8.314851084645534e-05, Test_loss: 6.405851952368244e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████▍                       | 701/1000 [13:40<05:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 8.903300420656923e-05, Test_loss: 6.335362755158886e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████▎                   | 751/1000 [14:25<04:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 8.272207690294766e-05, Test_loss: 6.28645642496481e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▎               | 801/1000 [15:09<03:24,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 8.29183598196121e-05, Test_loss: 6.823502255992069e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████▏           | 851/1000 [15:54<02:37,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 8.515440507806719e-05, Test_loss: 6.29557874655499e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████▏       | 901/1000 [16:40<01:41,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 8.272840215708821e-05, Test_loss: 6.381884415012402e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████▏   | 951/1000 [17:24<00:46,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 8.256786324117067e-05, Test_loss: 6.347938194802996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [17:59<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.05548772455693431\n",
      "L2 Error  of Temp: 0.003387282983447021\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.06231079157950656\n",
      "L2 Error  of Temp: 0.004385090019907279\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/mixing_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.46828623])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
